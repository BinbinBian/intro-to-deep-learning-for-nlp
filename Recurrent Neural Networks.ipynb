{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# RNN using LSTM \n",
    "       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RNN-rolled.png\"/ width=\"80px\" height=\"80px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RNN-unrolled.png\"/ width=\"400px\" height=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/LSTM3-chain.png\"/ width=\"800px\" height=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_source: http://colah.github.io/posts/2015-08-Understanding-LSTMs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.text import one_hot,text_to_word_sequence,base_filter\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n"
     ]
    }
   ],
   "source": [
    "DATA_DIRECTORY = os.path.join('data')\n",
    "print DATA_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIRECTORY,\"male_blog_list.txt\"),\"rb\") as male_file:\n",
    "    male_posts= pickle.load(male_file)\n",
    "with open(os.path.join(DATA_DIRECTORY,\"female_blog_list.txt\"),\"rb\") as female_file:\n",
    "    female_posts = pickle.load(female_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_male_posts = []\n",
    "filtered_female_posts = []\n",
    "\n",
    "for post_male in male_posts:\n",
    "    if len(post_male) == 0:\n",
    "        continue\n",
    "    post_male = re.sub('\\n','',post_male)\n",
    "    post_male = re.sub('\\\\\\\\','',post_male)\n",
    "    filtered_male_posts.append(post_male)\n",
    "\n",
    "for post_female in female_posts:\n",
    "    if len(post_female) == 0:\n",
    "        continue\n",
    "    post_female = re.sub('\\n','',post_female)\n",
    "    post_female = re.sub('\\\\\\\\','',post_female)\n",
    "    filtered_female_posts.append(post_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_posts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_posts.extend(filtered_male_posts)\n",
    "all_posts.extend(filtered_female_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i'm gonna work on my around the world today and hopefully get half of the paper done. Then i am going to the 20 hour famine at my church.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_posts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4842, 2595, 2247)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_posts),len(filtered_male_posts),len(filtered_female_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0 for male, 1 for female\n",
    "concatenate_array_rnn = np.concatenate((np.zeros(len(filtered_male_posts)),np.ones(len(filtered_female_posts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_list = list(set(''.join(all_posts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(char_list))\n",
    "indices_char = dict((i, c) for i, c in enumerate(char_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_indices = {'male':0,'female':1}\n",
    "indices_label = {0:'male',1:'female'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remarks by Al Gore May 26, 2004 As Prepared  George W. Bush promised us a foreign policy with humility. Instead, he has brought us humiliation in the eyes of the world.  He promised to \"restore honor and integrity to the White House.\" Instead, he has brought deep dishonor to our country and built a durable reputation as the most dishonest President since Richard Nixon.  Honor? He decided not to honor the Geneva Convention. Just as he would not honor the United Nations, international treaties, the opinions of our allies, the role of Congress and the courts, or what Jefferson described as \"a decent respect for the opinion of mankind.\" He did not honor the advice, experience and judgment of our military leaders in designing his invasion of Iraq. And now he will not honor our fallen dead by attending any funerals or even by permitting photos of their flag-draped coffins.  How did we get from September 12th , 2001, when a leading French newspaper ran a giant headline with the words \"We Are All Americans Now\" and when we had the good will and empathy of all the world -- to the horror that we all felt in witnessing the pictures of torture in Abu Ghraib.  To begin with, from its earliest days in power, this administration sought to radically destroy the foreign policy consensus that had guided America since the end of World War II. The long successful strategy of containment was abandoned in favor of the new strategy of \"preemption.\" And what they meant by preemption was not the inherent right of any nation to act preemptively against an imminent threat to its national security, but rather an exotic new approach that asserted a unique and unilateral U.S. right to ignore international law wherever it wished to do so and take military action against any nation, even in circumstances where there was no imminent threat. All that is required, in the view of Bush\\'s team is the mere assertion of a possible, future threat - and the assertion need be made by only one person, the President.  More disturbing still was their frequent use of the word \"dominance\" to describe their strategic goal, because an American policy of dominance is as repugnant to the rest of the world as the ugly dominance of the helpless, naked Iraqi prisoners has been to the American people. Dominance is as dominance does.  Dominance is not really a strategic policy or political philosophy at all. It is a seductive illusion that tempts the powerful to satiate their hunger for more power still by striking a Faustian bargain. And as always happens - sooner or later - to those who shake hands with the devil, they find out too late that what they have given up in the bargain is their soul.  One of the clearest indications of the impending loss of intimacy with one\\'s soul is the failure to recognize the existence of a soul in those over whom power is exercised, especially if the helpless come to be treated as animals, and degraded. We also know - and not just from De Sade and Freud - the psychological proximity between sexual depravity and other people\\'s pain. It has been especially shocking and awful to see these paired evils perpetrated so crudely and cruelly in the name of America.  Those pictures of torture and sexual abuse came to us embedded in a wave of news about escalating casualties and growing chaos enveloping our entire policy in Iraq. But in order understand the failure of our overall policy, it is important to focus specifically on what happened in the Abu Ghraib prison, and ask whether or not those actions were representative of who we are as Americans? Obviously the quick answer is no, but unfortunately it\\'s more complicated than that.  There is good and evil in every person. And what makes the United States special in the history of nations is our commitment to the rule of law and our carefully constructed system of checks and balances. Our natural distrust of concentrated power and our devotion to openness and democracy are what have lead us as a people to consistently choose good over evil in our collective aspirations more than the people any other nation.  Our founders were insightful students of human nature. They feared the abuse of power because they understood that every human being has not only \"better angels\" in his nature, but also an innate vulnerability to temptation - especially the temptation to abuse power over others.  Our founders understood full well that a system of checks and balances is needed in our constitution because every human being lives with an internal system of checks and balances that cannot be relied upon to produce virtue if they are allowed to attain an unhealthy degree of power over their fellow citizens.  Listen then to the balance of internal impulses described by specialist Charles Graner when confronted by one of his colleagues, Specialist Joseph M. Darby, who later became a courageous whistleblower. When Darby asked him to explain his actions documented in the photos, Graner replied: \"The Christian in me says it\\'s wrong, but the Corrections Officer says, \\'I love to make a groan man piss on himself.\"  What happened at the prison, it is now clear, was not the result of random acts by \"a few bad apples,\" it was the natural consequence of the Bush Administration policy that has dismantled those wise constraints and has made war on America\\'s checks and balances.  The abuse of the prisoners at Abu Ghraib flowed directly from the abuse of the truth that characterized the Administration\\'s march to war and the abuse of the trust that had been placed in President Bush by the American people in the aftermath of September 11th.  There was then, there is now and there would have been regardless of what Bush did, a threat of terrorism that we would have to deal with. But instead of making it better, he has made it infinitely worse. We are less safe because of his policies. He has created more anger and righteous indignation against us as Americans than any leader of our country in the 228 years of our existence as a nation -- because of his attitude of contempt for any person, institution or nation who disagrees with him.  He has exposed Americans abroad and Americans in every U.S. town and city to a greater danger of attack by terrorists because of his arrogance, willfulness, and bungling at stirring up hornet\\'s nests that pose no threat whatsoever to us. And by then insulting the religion and culture and tradition of people in other countries. And by pursuing policies that have resulted in the deaths of thousands of innocent men, women and children, all of it done in our name.  President Bush said in his speech Monday night that the war in Iraq is \"the central front in the war on terror.\" It\\'s not the central front in the war on terror, but it has unfortunately become the central recruiting office for terrorists. [Dick Cheney said, \"This war may last the rest of our lives.] The unpleasant truth is that President Bush\\'s utter incompetence has made the world a far more dangerous place and dramatically increased the threat of terrorism against the United States. Just yesterday, the International Institute of Strategic Studies reported that the Iraq conflict \" has arguable focused the energies and resources of Al Qaeda and its followers while diluting those of the global counterterrorism coalition.\" The ISS said that in the wake of the war in Iraq Al Qaeda now has more than 18,000 potential terrorists scattered around the world and the war in Iraq is swelling its ranks.  The war plan was incompetent in its rejection of the advice from military professionals and the analysis of the intelligence was incompetent in its conclusion that our soldiers would be welcomed with garlands of flowers and cheering crowds. Thus we would not need to respect the so-called Powell doctrine of overwhelming force.  There was also in Rumsfeld\\'s planning a failure to provide security for nuclear materials, and to prevent widespread lawlessness and looting.  Luckily, there was a high level of competence on the part of our soldiers even though they were denied the tools and the numbers they needed for their mission. What a disgrace that their families have to hold bake sales to buy discarded Kevlar vests to stuff into the floorboards of the Humvees! Bake sales for body armor.  And the worst still lies ahead. General Joseph Hoar, the former head of the Marine Corps, said \"I believe we are absolutely on the brink of failure. We are looking into the abyss.\"  When a senior, respected military leader like Joe Hoar uses the word \"abyss\", then the rest of us damn well better listen. Here is what he means: more American soldiers dying, Iraq slipping into worse chaos and violence, no end in sight, with our influence and moral authority seriously damaged.  Retired Marine Corps General Anthony Zinni, who headed Central Command before becoming President Bush\\'s personal emissary to the Middle East, said recently that our nation\\'s current course is \"headed over Niagara Falls.\"  The Commander of the 82nd Airborne Division, Army Major General Charles H. Swannack, Jr., asked by the Washington Post whether he believes the United States is losing the war in Iraq, replied, \"I think strategically, we are.\" Army Colonel Paul Hughes, who directed strategic planning for the US occupation authority in Baghdad, compared what he sees in Iraq to the Vietnam War, in which he lost his brother: \"I promised myself when I came on active duty that I would do everything in my power to prevent that ... from happening again. \" Noting that Vietnam featured a pattern of winning battles while losing the war, Hughes added \"unless we ensure that we have coherence in our policy, we will lose strategically.\"  The White House spokesman, Dan Bartlett was asked on live television about these scathing condemnations by Generals involved in the highest levels of Pentagon planning and he replied, \"Well they\\'re retired, and we take our advice from active duty officers.\"  But amazingly, even active duty military officers are speaking out against President Bush. For example, the Washington Post quoted an unnamed senior General at the Pentagon as saying, \" the current OSD (Office of the Secretary of Defense) refused to listen or adhere to military advice.\" Rarely if ever in American history have uniformed commanders felt compelled to challenge their commander in chief in public.  The Post also quoted an unnamed general as saying, \"Like a lot of senior Army guys I\\'m quite angry\" with Rumsfeld and the rest of the Bush Administration. He listed two reasons. \"I think they are going to break the Army,\" he said, adding that what really incites him is \"I don\\'t think they care.\"  In his upcoming book, Zinni blames the current catastrophe on the Bush team\\'s incompetence early on. \"In the lead-up to the Iraq war, and its later conduct,\" he writes, \"I saw at a minimum, true dereliction, negligence and irresponsibility, at worst, lying, incompetence and corruption.\"  Zinni\\'s book will join a growing library of volumes by former advisors to Bush -- including his principal advisor on terrorism, Richard Clarke; his principal economic policy advisor, former Treasury Secretary Paul O\\'Neill, former Ambassador Joe Wilson, who was honored by Bush\\'s father for his service in Iraq, and his former Domestic Adviser on faith-based organizations, John Dilulio, who said, \"There is no precedent in any modern White House for what is going on in this one: a complete lack of a policy apparatus. What you\\'ve got is everything, and I mean everything, run by the political arm. It\\'s the reign of the Mayberry Machiavellis.\"  Army Chief of Staff General Eric Shinseki told Congress in February that the occupation could require \"several hundred thousand troops.\" But because Rumsfeld and Bush did not want to hear disagreement with their view that Iraq could be invaded at a much lower cost, Shinseki was hushed and then forced out.  And as a direct result of this incompetent plan and inadequate troop strength, young soldiers were put in an untenable position. For example, young reservists assigned to the Iraqi prisons were called up without training or adequate supervision, and were instructed by their superiors to \"break down\" prisoners in order to prepare them for interrogation.  To make matters worse, they were placed in a confusing situation where the chain of command was criss-crossed between intelligence gathering and prison administration, and further confused by an unprecedented mixing of military and civilian contractor authority.  The soldiers who are accused of committing these atrocities are, of course, responsible for their own actions and if found guilty, must be severely and appropriately punished. But they are not the ones primarily responsible for the disgrace that has been brought upon the United States of America.  Private Lynndie England did not make the decision that the United States would not observe the Geneva Convention. Specialist Charles Graner was not the one who approved a policy of establishing an American Gulag of dark rooms with naked prisoners to be \"stressed\" and even - we must use the word - tortured - to force them to say things that legal procedures might not induce them to say.  These policies were designed and insisted upon by the Bush White House. Indeed, the President\\'s own legal counsel advised him specifically on the subject. His secretary of defense and his assistants pushed these cruel departures from historic American standards over the objections of the uniformed military, just as the Judge Advocates General within the Defense Department were so upset and opposed that they took the unprecedented step of seeking help from a private lawyer in this city who specializes in human rights and said to him, \"There is a calculated effort to create an atmosphere of legal ambiguity\" where the mistreatment of prisoners is concerned.\"  Indeed, the secrecy of the program indicates an understanding that the regular military culture and mores would not support these activities and neither would the American public or the world community. Another implicit acknowledgement of violations of accepted standards of behavior is the process of farming out prisoners to countries less averse to torture and giving assignments to private contractors  President Bush set the tone for our attitude for suspects in his State of the Union address. He noted that more than 3,000 \"suspected terrorists\" had been arrested in many countries and then he added, \"and many others have met a different fate. Let\\'s put it this way: they are no longer a problem to the United States and our allies.\"  George Bush promised to change the tone in Washington. And indeed he did. As many as 37 prisoners may have been murdered while in captivity, though the numbers are difficult to rely upon because in many cases involving violent death, there were no autopsies.  How dare they blame their misdeeds on enlisted personnel from a Reserve unit in upstate New York. President Bush owes more than one apology. On the list of those he let down are the young soldiers who are themselves apparently culpable, but who were clearly put into a moral cesspool. The perpetrators as well as the victims were both placed in their relationship to one another by the policies of George W. Bush.  How dare the incompetent and willful members of this Bush/Cheney Administration humiliate our nation and our people in the eyes of the world and in the conscience of our own people. How dare they subject us to such dishonor and disgrace. How dare they drag the good name of the United States of America through the mud of Saddam Hussein\\'s torture prison.  David Kay concluded his search for weapons of mass destruction in Iraq with the famous verdict: \"we were all wrong.\" And for many Americans, Kay\\'s statement seemed to symbolize the awful collision between Reality and all of the false and fading impressions President Bush had fostered in building support for his policy of going to war.  Now the White House has informed the American people that they were also \"all wrong\" about their decision to place their faith in Ahmed Chalabi, even though they have paid him 340,000 dollars per month. 33 million dollars (CHECK) and placed him adjacent to Laura Bush at the State of the Union address. Chalabi had been convicted of fraud and embezzling 70 million dollars in public funds from a Jordanian bank, and escaped prison by fleeing the country. But in spite of that record, he had become one of key advisors to the Bush Administration on planning and promoting the War against Iraq.  And they repeatedly cited him as an authority, perhaps even a future president of Iraq. Incredibly, they even ferried him and his private army into Baghdad in advance of anyone else, and allowed him to seize control over Saddam\\'s secret papers.  Now they are telling the American people that he is a spy for Iran who has been duping the President of the United States for all these years.  One of the Generals in charge of this war policy went on a speaking tour in his spare time to declare before evangelical groups that the US is in a holy war as \"Christian Nation battling Satan.\" This same General Boykin was the person who ordered the officer who was in charge of the detainees in Guantanamo Bay to extend his methods to Iraq detainees, prisoners. ... The testimony from the prisoners is that they were forced to curse their religion Bush used the word \"crusade\" early on in the war against Iraq, and then commentators pointed out that it was singularly inappropriate because of the history and sensitivity of the Muslim world and then a few weeks later he used it again.  \"We are now being viewed as the modern Crusaders, as the modern colonial power in this part of the world,\" Zinni said.  What a terrible irony that our country, which was founded by refugees seeking religious freedom - coming to America to escape domineering leaders who tried to get them to renounce their religion - would now be responsible for this kind of abuse..  Ameen Saeed al-Sheikh told the Washington Post that he was tortured and ordered to denounce Islam and after his leg was broken one of his torturers started hitting it while ordering him to curse Islam and then, \" they ordered me to thank Jesus that I\\'m alive.\" Others reported that they were forced to eat pork and drink alcohol.  In my religious tradition, I have been taught that \"ye shall know them by their fruits. Do men gather grapes of thorns, or figs of thistles? Even so, every good tree bringeth forth good fruit; but a corrupt tree bringeth forth evil fruit... Wherefore by their fruits ye shall know them.\"  The President convinced a majority of the country that Saddam Hussein was responsible for attacking us on September 11th. But in truth he had nothing whatsoever to do with it. The President convinced the country with a mixture of forged documents and blatantly false assertions that Saddam was in league with Al Qaeda, and that he was \"indistinguishable\" from Osama bin Laden.  He asked the nation , in his State of the Union address, to \"imagine\" how terrified we should be that Saddam was about to give nuclear weapons to terrorists and stated repeatedly that Iraq posed a grave and gathering threat to our nation. He planted the seeds of war, and harvested a whirlwind. And now, the \"corrupt tree\" of a war waged on false premises has brought us the \"evil fruit\" of Americans torturing and humiliating prisoners.  In my opinion, John Kerry is dealing with this unfolding tragedy in an impressive and extremely responsible way. Our nation\\'s best interest lies in having a new president who can turn a new page, sweep clean with a new broom, and take office on January 20th of next year with the ability to make a fresh assessment of exactly what our nation\\'s strategic position is as of the time the reigns of power are finally wrested from the group of incompetents that created this catastrophe.  Kerry should not tie his own hands by offering overly specific, detailed proposals concerning a situation that is rapidly changing and unfortunately, rapidly deteriorating, but should rather preserve his, and our country\\'s, options, to retrieve our national honor as soon as this long national nightmare is over.  Eisenhower did not propose a five-point plan for changing America\\'s approach to the Korean War when he was running for president in 1952.  When a business enterprise finds itself in deep trouble that is linked to the failed policies of the current CEO the board of directors and stockholders usually say to the failed CEO, \"Thank you very much, but we\\'re going to replace you now with a new CEO -- one less vested in a stubborn insistence on staying the course, even if that course is, in the words of General Zinni, \"Headed over Niagara Falls.\"  One of the strengths of democracy is the ability of the people to regularly demand changes in leadership and to fire a failing leader and hire a new one with the promise of hopeful change. That is the real solution to America\\'s quagmire in Iraq. But, I am keenly aware that we have seven months and twenty five days remaining in this president\\'s current term of office and that represents a time of dangerous vulnerability for our country because of the demonstrated incompetence and recklessness of the current administration.  It is therefore essential that even as we focus on the fateful choice, the voters must make this November that we simultaneously search for ways to sharply reduce the extraordinary danger that we face with the current leadership team in place. It is for that reason that I am calling today for Republicans as well as Democrats to join me in asking for the immediate resignations of those immediately below George Bush and Dick Cheney who are most responsible for creating the catastrophe that we are facing in Iraq.  We desperately need a national security team with at least minimal competence because the current team is making things worse with each passing day. They are endangering the lives of our soldiers, and sharply increasing the danger faced by American citizens everywhere in the world, including here at home. They are enraging hundreds of millions of people and embittering an entire generation of anti-Americans whose rage is already near the boiling point.  We simply cannot afford to further increase the risk to our country with more blunders by this team. Donald Rumsfeld, as the chief architect of the war plan, should resign today. His deputies Paul Wolfowitz, Douglas Feith and his intelligence chief Stephen Cambone should also resign. The nation is especially at risk every single day that Rumsfeld remains as Secretary of Defense.  Condoleeza Rice, who has badly mishandled the coordination of national security policy, should also resign immediately.  George Tenet should also resign. I want to offer a special word about George Tenet, because he is a personal friend and I know him to be a good and decent man. It is especially painful to call for his resignation, but I have regretfully concluded that it is extremely important that our country have new leadership at the CIA immediately.  As a nation, our greatest export has always been hope: hope that through the rule of law people can be free to pursue their dreams, that democracy can supplant repression and that justice, not power, will be the guiding force in society. Our moral authority in the world derived from the hope anchored in the rule of law. With this blatant failure of the rule of law from the very agents of our government, we face a great challenge in restoring our moral authority in the world and demonstrating our commitment to bringing a better life to our global neighbors.  During Ronald Reagan\\'s Presidency, Secretary of Labor Ray Donovan was accused of corruption, but eventually, after a lot of publicity, the indictment was thrown out by the Judge. Donovan asked the question, \"Where do I go to get my reputation back?\" President Bush has now placed the United States of America in the same situation. Where do we go to get our good name back?  The answer is, we go where we always go when a dramatic change is needed. We go to the ballot box, and we make it clear to the rest of the world that what\\'s been happening in America for the last four years, and what America has been doing in Iraq for the last two years, really is not who we are. We, as a people, at least the overwhelming majority of us, do not endorse the decision to dishonor the Geneva Convention and the Bill of Rights....  Make no mistake, the damage done at Abu Ghraib is not only to America\\'s reputation and America\\'s strategic interests, but also to America\\'s spirit. It is also crucial for our nation to recognize - and to recognize quickly - that the damage our nation has suffered in the world is far, far more serious than President Bush\\'s belated and tepid response would lead people to believe. Remember how shocked each of us, individually, was when we first saw those hideous images. The natural tendency was to first recoil from the images, and then to assume that they represented a strange and rare aberration that resulted from a few twisted minds or, as the Pentagon assured us, \"a few bad apples.\"  But as today\\'s shocking news reaffirms yet again, this was not rare. It was not an aberration. Today\\'s New York Times reports that an Army survey of prisoner deaths and mistreatment in Iraq and Afghanisatan \"show a widespread pattern of abuse involving more military units than previously known.\\'  Nor did these abuses spring from a few twisted minds at the lowest ranks of our military enlisted personnel. No, it came from twisted values and atrocious policies at the highest levels of our government. This was done in our name, by our leaders.  These horrors were the predictable consequence of policy choices that flowed directly from this administration\\'s contempt for the rule of law. And the dominance they have been seeking is truly not simply unworthy of America - it is also an illusory goal in its own right.  Our world is unconquerable because the human spirit is unconquerable, and any national strategy based on pursuing the goal of domination is doomed to fail because it generates its own opposition, and in the process, creates enemies for the would-be dominator.  A policy based on domination of the rest of the world not only creates enemies for the United States and creates recruits for Al Qaeda, it also undermines the international cooperation that is essential to defeating the efforts of terrorists who wish harm and intimidate Americans.  Unilateralism, as we have painfully seen in Iraq, is its own reward. Going it alone may satisfy a political instinct but it is dangerous to our military, even without their Commander in Chief taunting terrorists to \"bring it on.\"  Our troops are stretched thin and exhausted not only because Secretary Rumsfeld contemptuously dismissed the advice of military leaders on the size of the needed force - but also because President Bush\\'s contempt for traditional allies and international opinion left us without a real coalition to share the military and financial burden of the war and the occupation. Our future is dependent upon increasing cooperation and interdependence in a world tied ever more closely together by technologies of communications and travel. The emergence of a truly global civilization has been accompanied by the recognition of truly global challenges that require global responses that, as often as not, can only be led by the United States - and only if the United States restores and maintains its moral authority to lead.  Make no mistake, it is precisely our moral authority that is our greatest source of strength, and it is precisely our moral authority that has been recklessly put at risk by the cheap calculations and mean compromises of conscience wagered with history by this willful president.  Listen to the way Israel\\'s highest court dealt with a similar question when, in 1999, it was asked to balance due process rights against dire threats to the security of its people:  \"This is the destiny of democracy, as not all means are acceptable to it, and not all practices employed by its enemies are open before it. Although a democracy must often fight with one hand tied behind its back, it nonetheless has the upper hand. Preserving the Rule of Law and recognition of an individual\\'s liberty constitutes an important component in its understanding of security. At the end of the day they (add to) its strength.\"  The last and best description of America\\'s meaning in the world is still the definitive formulation of Lincoln\\'s annual message to Congress on December 1, 1862:  \"The occasion is piled high with difficulty, and we must rise - with the occasion. As our case is new, so we must think anew, and act anew. We must disenthrall ourselves, and then we shall save our country. Fellow citizens, we cannot escape history...the fiery trial through which we pass will light us down in honor or dishonor to the latest generation...We shall nobly save, or meanly lose the last best hope of earth...The way is plain, peaceful, generous, just - a way which, if followed, the world will forever applaud, and God must forever bless.\"  It is now clear that their obscene abuses of the truth and their unforgivable abuse of the trust placed in them after 9/11 by the American people led directly to the abuses of the prisoners in Abu Ghraib prison and, we are now learning, in many other similar facilities constructed as part of Bush\\'s Gulag, in which, according to the Red Cross, 70 to 90 percent of the victims are totally innocent of any wrongdoing.  The same dark spirit of domination has led them to - for the first time in American history - imprison American citizens with no charges, no right to see a lawyer, no right to notify their family, no right to know of what they are accused, and no right to gain access to any court to present an appeal of any sort. The Bush Admistration has even acquired the power to compel librarians to tell them what any American is reading, and to compel them to keep silent about the request - or else the librarians themselves can also be imprisoned.  They have launched an unprecedented assault on civil liberties, on the right of the courts to review their actions, on the right of the Congress to have information to how they are spending the public\\'s money and the right of the news media to have information about the policies they are pursuing.  The same pattern characterizes virtually all of their policies. They resent any constraint as an insult to their will to dominate and exercise power. Their appetite for power is astonishing. It has led them to introduce a new level of viciousness in partisan politics. It is that viciousness that led them to attack as unpatriotic, Senator Max Cleland, who lost three limbs in combat during the Vietnam War.  The president episodically poses as a healer and \"uniter\". If he president really has any desire to play that role, then I call upon him to condemn Rush Limbaugh - perhaps his strongest political supporter - who said that the torture in Abu Ghraib was a \"brilliant maneuver\" and that the photos were \"good old American pornography,\" and that the actions portrayed were simply those of \"people having a good time and needing to blow off steam.\"  This new political viciousness by the President and his supporters is found not only on the campaign trail, but in the daily operations of our democracy. They have insisted that the leaders of their party in the Congress deny Democrats any meaningful role whatsoever in shaping legislation, debating the choices before us as a people, or even to attend the all-important conference committees that reconcile the differences between actions by the Senate and House of Representatives.  The same meanness of spirit shows up in domestic policies as well. Under the Patriot Act, Muslims, innocent of any crime, were picked up, often physically abused, and held incommunicado indefinitely. What happened in Abu Ghraib was difference not of kind, but of degree.  Differences of degree are important when the subject is torture. The apologists for what has happened do have points that should be heard and clearly understood. It is a fact that every culture and every politics sometimes expresses itself in cruelty. It is also undeniably true that other countries have and do torture more routinely, and far more brutally, than ours has. George Orwell once characterized life in Stalin\\'s Russia as \"a boot stamping on a human face forever.\" That was the ultimate culture of cruelty, so ingrained, so organic, so systematic that everyone in it lived in terror, even the terrorizers. And that was the nature and degree of state cruelty in Saddam Hussein\\'s Iraq.  We all know these things, and we need not reassure ourselves and should not congratulate ourselves that our society is less cruel than some others, although it is worth noting that there are many that are less cruel than ours. And this searing revelation at Abu Ghraib should lead us to examine more thoroughly the routine horrors in our domestic prison system.  But what we do now, in reaction to Abu Ghraib will determine a great deal about who we are at the beginning of the 21st century. It is important to note that just as the abuses of the prisoners flowed directly from the policies of the Bush White House, those policies flowed not only from the instincts of the president and his advisors, but found support in shifting attitudes on the part of some in our country in response to the outrage and fear generated by the attack of September 11th.  The president exploited and fanned those fears, but some otherwise sensible and levelheaded Americans fed them as well. I remember reading genteel-sounding essays asking publicly whether or not the prohibitions against torture were any longer relevant or desirable. The same grotesque misunderstanding of what is really involved was responsible for the tone in the memo from the president\\'s legal advisor, Alberto Gonzalez, who wrote on January 25, 2002, that 9/11 \"renders obsolete Geneva\\'s strict limitations on questioning of enemy prisoners and renders quaint some of its provisions.\"  We have seen the pictures. We have learned the news. We cannot unlearn it; it is part of us. The important question now is, what will we do now about torture. Stop it? Yes, of course. But that means demanding all of the facts, not covering them up, as some now charge the administration is now doing. One of the whistleblowers at Abu Ghraib, Sergeant Samuel Provance, told ABC News a few days ago that he was being intimidated and punished for telling the truth. \"There is definitely a coverup,\" Provance said. \"I feel like I am being punished for being honest.\"  The abhorrent acts in the prison were a direct consequence of the culture of impunity encouraged, authorized and instituted by Bush and Rumsfeld in their statements that the Geneva Conventions did not apply. The apparent war crimes that took place were the logical, inevitable outcome of policies and statements from the administration.  To me, as glaring as the evidence of this in the pictures themselves was the revelation that it was established practice for prisoners to be moved around during ICRC visits so that they would not be available for visits. That, no one can claim, was the act of individuals. That was policy set from above with the direct intention to violate US values it was to be upholding. It was the kind of policy we see - and criticize in places like China and Cuba.  Moreover, the administration has also set up the men and women of our own armed forces for payback the next time they are held as prisoners. And for that, this administration should pay a very high price. One of the most tragic consequences of these official crimes is that it will be very hard for any of us as Americans - at least for a very long time - to effectively stand up for human rights elsewhere and criticize other governments, when our policies have resulted in our soldiers behaving so monstrously. This administration has shamed America and deeply damaged the cause of freedom and human rights everywhere, thus undermining the core message of America to the world.  President Bush offered a brief and half-hearted apology to the Arab world - but he should apologize to the American people for abandoning the Geneva Conventions. He also owes an apology to the U.S. Army for cavalierly sending them into harm\\'s way while ignoring the best advice of their commanders. Perhaps most importantly of all, he should apologize to all those men and women throughout our world who have held the ideal of the United States of America as a shining goal, to inspire their hopeful efforts to bring about justice under a rule of law in their own lands. Of course, the problem with all these legitimate requests is that a sincere apology requires an admission of error, a willingness to accept responsibility and to hold people accountable. And President Bush is not only unwilling to acknowledge error. He has thus far been unwilling to hold anyone in his administration accountable for the worst strategic and military miscalculations and mistakes in the history of the United States of America.  He is willing only to apologize for the alleged erratic behavior of a few low-ranking enlisted people, who he is scapegoating for his policy fiasco.  In December of 2000, even though I strongly disagreed with the decision by the U.S. Supreme Court to order a halt to the counting of legally cast ballots, I saw it as my duty to reaffirm my own strong belief that we are a nation of laws and not only accept the decision, but do what I could to prevent efforts to delegitimize George Bush as he took the oath of office as president.  I did not at that moment imagine that Bush would, in the presidency that ensued, demonstrate utter contempt for the rule of law and work at every turn to frustrate accountability...  So today, I want to speak on behalf of those Americans who feel that President Bush has betrayed our nation\\'s trust, those who are horrified at what has been done in our name, and all those who want the rest of the world to know that we Americans see the abuses that occurred in the prisons of Iraq, Afghanistan, Guantanamo and secret locations as yet undisclosed as completely out of keeping with the character and basic nature of the American people and at odds with the principles on which America stands.  I believe we have a duty to hold President Bush accountable - and I believe we will. As Lincoln said at our time of greatest trial, \"We - even we here - hold the power, and bear the responsibility.\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_posts[227]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38794, 227)\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 0\n",
    "i = 0\n",
    "MAX_INDEX = 0\n",
    "for i,n in enumerate(all_posts):\n",
    "    \n",
    "    if len(n) > MAX_LENGTH:\n",
    "        MAX_LENGTH = len(n)\n",
    "        MAX_INDEX = i\n",
    "        \n",
    "print(MAX_LENGTH,MAX_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blog_to_char_seq(blog):\n",
    "    blog_chars = list(blog)\n",
    "    blog_chars_indices = list(map(lambda char: char_indices[char], blog_chars))\n",
    "    return sequence.pad_sequences([blog_chars_indices], maxlen=MAX_LENGTH)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((4842, 5000), (4842,))\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for n, l in zip(all_posts, concatenate_array_rnn):\n",
    "    X.append(blog_to_char_seq(n))\n",
    "    y.append(l)\n",
    "    \n",
    "X = np.array(X).astype(np.uint8)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "dimension = 128\n",
    "input_dimension = 128\n",
    "output_dimension = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(char_list), 64, input_length=MAX_LENGTH, mask_zero=True))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='sgd', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3921 samples, validate on 436 samples\n",
      "Epoch 1/10\n",
      "1376/3921 [=========>....................] - ETA: 761s - loss: 0.2502 - acc: 0.5022"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,\n",
    "          batch_size=32,nb_epoch=10,\n",
    "          validation_split=0.1,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927/927 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25045589757068515, 0.58036677396284597]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_rnn,y_test_rnn,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_rnn,x_test_rnn,y_train_rnn,y_test_rnn = train_test_split(np.concatenate((male_one_hot, female_one_hot)),y_rnn,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train_rnn shape:', (3706, 100), (3706,))\n",
      "('x_test_rnn shape:', (927, 100), (927,))\n"
     ]
    }
   ],
   "source": [
    "maxlen = 100\n",
    "x_train_rnn = sequence.pad_sequences(x_train_rnn,maxlen=maxlen)\n",
    "x_test_rnn = sequence.pad_sequences(x_test_rnn,maxlen=maxlen)\n",
    "\n",
    "print('x_train_rnn shape:', x_train_rnn.shape,y_train_rnn.shape)\n",
    "print('x_test_rnn shape:', x_test_rnn.shape,y_test_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927/927 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "predicted_output = model.predict(x_test_rnn,batch_size=32)\n",
    "predicted_classes = model.predict_classes(x_test_rnn, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['predicted','actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['predicted_class'] = predicted_classes.flatten()\n",
    "df['predicted'] = predicted_output.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['actual'] = y_test_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    927\n",
       "Name: predicted_class, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.predicted_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    509\n",
       "1    418\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3706, 100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TFIDF Vectorizer as an input instead of one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(decode_error='ignore', norm='l2')\n",
    "tfidf_male = vectorizer.fit_transform(filtered_male_posts)\n",
    "tfidf_female = vectorizer.fit_transform(filtered_female_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flattened_array_tfidf_male = tfidf_male.toarray()\n",
    "flattened_array_tfidf_female = tfidf_male.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concatenate_array_rnn = np.concatenate((np.zeros(len(flattened_array_tfidf_male)),np.ones(len(flattened_array_tfidf_female))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_rnn,x_test_rnn,y_train_rnn,y_test_rnn = train_test_split(np.concatenate((flattened_array_tfidf_male,flattened_array_tfidf_female)),concatenate_array_rnn,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "# x_train_rnn = sequence.pad_sequences(x_train_rnn,maxlen=maxlen)\n",
    "# x_test_rnn = sequence.pad_sequences(x_test_rnn,maxlen=maxlen)\n",
    "# print('x_train_rnn shape:', x_train_rnn.shape,y_train_rnn.shape)\n",
    "# print('x_test_rnn shape:', x_test_rnn.shape,y_test_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train_rnn shape:', (4152, 100), (4152,))\n",
      "('x_test_rnn shape:', (1038, 100), (1038,))\n"
     ]
    }
   ],
   "source": [
    "maxlen = 100\n",
    "x_train_rnn = sequence.pad_sequences(x_train_rnn,maxlen=maxlen)\n",
    "x_test_rnn = sequence.pad_sequences(x_test_rnn,maxlen=maxlen)\n",
    "print('x_train_rnn shape:', x_train_rnn.shape,y_train_rnn.shape)\n",
    "print('x_test_rnn shape:', x_test_rnn.shape,y_test_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "dimension = 128\n",
    "input_dimension = 128\n",
    "output_dimension = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, dimension))\n",
    "model.add(LSTM(output_dim = output_dimension, input_dim=input_dimension, return_sequences=False, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(LSTM(output_dim=output_dimension))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(input_dim=output_dimension, output_dim=1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4152 samples, validate on 1038 samples\n",
      "Epoch 1/10\n",
      "4152/4152 [==============================] - 25s - loss: 0.2814 - val_loss: 0.2501\n",
      "Epoch 2/10\n",
      "4152/4152 [==============================] - 27s - loss: 0.2831 - val_loss: 0.2501\n",
      "Epoch 3/10\n",
      "4152/4152 [==============================] - 25s - loss: 0.2826 - val_loss: 0.2500\n",
      "Epoch 4/10\n",
      "4152/4152 [==============================] - 25s - loss: 0.2798 - val_loss: 0.2500\n",
      "Epoch 5/10\n",
      "4152/4152 [==============================] - 23s - loss: 0.2758 - val_loss: 0.2501\n",
      "Epoch 6/10\n",
      "4152/4152 [==============================] - 24s - loss: 0.2715 - val_loss: 0.2501\n",
      "Epoch 7/10\n",
      "4152/4152 [==============================] - 24s - loss: 0.2715 - val_loss: 0.2500\n",
      "Epoch 8/10\n",
      "4152/4152 [==============================] - 24s - loss: 0.2694 - val_loss: 0.2500\n",
      "Epoch 9/10\n",
      "4152/4152 [==============================] - 24s - loss: 0.2662 - val_loss: 0.2500\n",
      "Epoch 10/10\n",
      "4152/4152 [==============================] - 24s - loss: 0.2652 - val_loss: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcaf91d8750>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_rnn,y_train_rnn,batch_size=32,nb_epoch=10,validation_data=(x_test_rnn,y_test_rnn),show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038/1038 [==============================] - 4s     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/init/anaconda2/lib/python2.7/site-packages/keras/models.py:426: UserWarning: The \"show_accuracy\" argument is deprecated, instead you should pass the \"accuracy\" metric to the model at compile time:\n",
      "`model.compile(optimizer, loss, metrics=[\"accuracy\"])`\n",
      "  warnings.warn('The \"show_accuracy\" argument is deprecated, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24999907024219087"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_rnn,y_test_rnn,batch_size=32,show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['predicted','actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_output = model.predict(x_test_rnn,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038/1038 [==============================] - 4s     \n"
     ]
    }
   ],
   "source": [
    "df['pc'] = model.predict_classes(x_test_rnn, batch_size=32).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['predicted'] = predicted_output.flatten()\n",
    "df['actual'] = y_test_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "      <th>pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>0.499085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1038 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted  actual  pc\n",
       "0      0.499085       0   0\n",
       "1      0.499085       0   0\n",
       "2      0.499085       0   0\n",
       "3      0.499085       0   0\n",
       "4      0.499085       0   0\n",
       "5      0.499085       0   0\n",
       "6      0.499085       1   0\n",
       "7      0.499085       0   0\n",
       "8      0.499085       0   0\n",
       "9      0.499085       1   0\n",
       "10     0.499085       1   0\n",
       "11     0.499085       0   0\n",
       "12     0.499085       0   0\n",
       "13     0.499085       1   0\n",
       "14     0.499085       1   0\n",
       "15     0.499085       0   0\n",
       "16     0.499085       1   0\n",
       "17     0.499085       0   0\n",
       "18     0.499085       0   0\n",
       "19     0.499085       1   0\n",
       "20     0.499085       0   0\n",
       "21     0.499085       1   0\n",
       "22     0.499085       0   0\n",
       "23     0.499085       0   0\n",
       "24     0.499085       0   0\n",
       "25     0.499085       0   0\n",
       "26     0.499085       0   0\n",
       "27     0.499085       0   0\n",
       "28     0.499085       1   0\n",
       "29     0.499085       1   0\n",
       "...         ...     ...  ..\n",
       "1008   0.499085       0   0\n",
       "1009   0.499085       1   0\n",
       "1010   0.499085       0   0\n",
       "1011   0.499085       0   0\n",
       "1012   0.499085       0   0\n",
       "1013   0.499085       1   0\n",
       "1014   0.499085       1   0\n",
       "1015   0.499085       0   0\n",
       "1016   0.499085       0   0\n",
       "1017   0.499085       1   0\n",
       "1018   0.499085       0   0\n",
       "1019   0.499085       0   0\n",
       "1020   0.499085       1   0\n",
       "1021   0.499085       1   0\n",
       "1022   0.499085       0   0\n",
       "1023   0.499085       0   0\n",
       "1024   0.499085       0   0\n",
       "1025   0.499085       0   0\n",
       "1026   0.499085       1   0\n",
       "1027   0.499085       1   0\n",
       "1028   0.499085       1   0\n",
       "1029   0.499085       0   0\n",
       "1030   0.499085       1   0\n",
       "1031   0.499085       0   0\n",
       "1032   0.499085       0   0\n",
       "1033   0.499085       1   0\n",
       "1034   0.499085       1   0\n",
       "1035   0.499085       0   0\n",
       "1036   0.499085       0   0\n",
       "1037   0.499085       0   0\n",
       "\n",
       "[1038 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1038\n",
       "Name: pc, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1038,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1038, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "      <th>pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.495028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.495028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.495028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.495028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.495028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  actual  pc\n",
       "0   0.495028       1   0\n",
       "1   0.495028       0   0\n",
       "2   0.495028       1   0\n",
       "3   0.495028       1   0\n",
       "4   0.495028       1   0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Generation using RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading all the male text data into one string\n",
    "male_post = ' '.join(filtered_male_posts[:2])\n",
    "\n",
    "#building character set for the male posts\n",
    "character_set_male = set(male_post)\n",
    "#building two indices - character index and index of character\n",
    "char_indices = dict((c, i) for i, c in enumerate(character_set_male))\n",
    "indices_char = dict((i, c) for i, c in enumerate(character_set_male))\n",
    "\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 20\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(male_post) - maxlen, step):\n",
    "    sentences.append(male_post[i : i + maxlen])\n",
    "    next_chars.append(male_post[i + maxlen])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Vectorisation of input\n",
    "x_male = np.zeros((len(male_post),maxlen,len(character_set_male)),dtype=np.bool)\n",
    "y_male = np.zeros((len(male_post),len(character_set_male)),dtype=np.bool)\n",
    "\n",
    "print x_male.shape,y_male.shape\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_male[i, t, char_indices[char]] = 1\n",
    "    y_male[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print x_male.shape,y_male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Building the model to generate text with 2 layers\n",
    "auto_text_generating_male_model = Sequential()\n",
    "auto_text_generating_male_model.add(LSTM(len(character_set_male),512,return_sequences=True))\n",
    "auto_text_generating_male_model.add(Dropout(0.2))\n",
    "auto_text_generating_male_model.add(LSTM(512,512,return_sequences=False))\n",
    "auto_text_generating_male_model.add(Dropout(0.2))\n",
    "auto_text_generating_male_model.add(Dense(512,len(character_set_male)))\n",
    "auto_text_generating_male_model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_text_generating_male_model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to sample an index from a probability array\n",
    "def sample(a, diversity=0.75):\n",
    "    if random.random() > diversity:\n",
    "        return np.argmax(a)\n",
    "    while 1:\n",
    "        i = random.randint(0, len(a)-1)\n",
    "        if a[i] > random.random():\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1,10):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    auto_text_generating_male_model.fit(x_male, y_male, batch_size=128, nb_epoch=1)\n",
    "\n",
    "    start_index = random.randint(0, len(male_post) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.4, 0.6, 0.8]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = male_post[start_index : start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "        for iteration in range(400):\n",
    "            try:\n",
    "                x = np.zeros((1, maxlen, len(character_set_male)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = auto_text_generating_male_model.predict(x, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                #sys.stdout.write(next_char)\n",
    "                #sys.stdout.flush()\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        print sentence\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
